{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal ML, Uplift Modeling Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare winning model from Two-Model to Single-Model Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Two-Model Approach Evaluation ###\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'uplift_two_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[47], line 26\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Compare Two-Model and S-Learner\u001b[39;00m\n",
      "\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Two-Model Approach Evaluation ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m---> 26\u001b[0m evaluate_qini(\u001b[43muplift_two_model\u001b[49m, y_test, t_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwo-Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### S-Learner Evaluation ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     29\u001b[0m evaluate_qini(uplift_s_learner, y_test, t_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS-Learner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'uplift_two_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Enhanced Qini Evaluation\n",
    "def evaluate_qini(uplift, y_test, t_test, model_name):\n",
    "    qini = qini_auc_score(y_test, uplift, t_test)\n",
    "\n",
    "    # Use a loop to calculate uplift at different percentages\n",
    "    k_values = [i / 100 for i in range(1, 100)]  # Generate k as float values from 0.01 to 1\n",
    "    uplift_cumulative = []\n",
    "\n",
    "    for k in k_values:\n",
    "        uplift_k = uplift_at_k(y_test, uplift, t_test, strategy='overall', k=k)\n",
    "        uplift_cumulative.append(uplift_k)\n",
    "\n",
    "    print(f\"{model_name} Qini Score: {qini:.4f}\")\n",
    "\n",
    "    # Plot the Qini Curve\n",
    "    plt.plot(k_values, uplift_cumulative, label=f'{model_name} Model')\n",
    "    plt.plot([0, 1], [0, max(uplift_cumulative)], '--', label='Random')\n",
    "    plt.xlabel('Proportion of Population Targeted')\n",
    "    plt.ylabel('Cumulative Uplift')\n",
    "    plt.title(f'Qini Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Compare Two-Model and S-Learner\n",
    "print(\"### Two-Model Approach Evaluation ###\")\n",
    "evaluate_qini(uplift_two_model, y_test, t_test, \"Two-Model\")\n",
    "\n",
    "print(\"### S-Learner Evaluation ###\")\n",
    "evaluate_qini(uplift_s_learner, y_test, t_test, \"S-Learner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Tabular Comparison of Qini Scores\n",
    "qini_two_model = qini_auc_score(y_test, uplift_two_model, t_test)\n",
    "qini_s_learner = qini_auc_score(y_test, uplift_s_learner, t_test)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Two-Model', 'S-Learner'],\n",
    "    'Qini Score': [qini_two_model, qini_s_learner]\n",
    "})\n",
    "print(\"\\n### Qini Score Comparison ###\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklift.metrics import uplift_at_k,qini_auc_score\n",
    "from sklift.datasets import fetch_hillstrom # our dataset!\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from causalml.metrics import auuc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64000 entries, 0 to 63999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   recency          64000 non-null  int64  \n",
      " 1   history_segment  64000 non-null  object \n",
      " 2   history          64000 non-null  float64\n",
      " 3   mens             64000 non-null  int64  \n",
      " 4   womens           64000 non-null  int64  \n",
      " 5   zip_code         64000 non-null  object \n",
      " 6   newbie           64000 non-null  int64  \n",
      " 7   channel          64000 non-null  object \n",
      " 8   segment          64000 non-null  object \n",
      " 9   visit            64000 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(4)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "recency            0\n",
      "history_segment    0\n",
      "history            0\n",
      "mens               0\n",
      "womens             0\n",
      "zip_code           0\n",
      "newbie             0\n",
      "channel            0\n",
      "segment            0\n",
      "visit              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load Hillstrom dataset\n",
    "def load_hillstrom():\n",
    "    dataset = fetch_hillstrom()\n",
    "    df = dataset.data\n",
    "    # Segment has 3 options, womens email, mens email and no email, so we can create 'treatment' by choosing one of the two treatments here\n",
    "    df['segment'] = dataset.treatment\n",
    "    # There are 3 outcomes, visit, conversion and spend, we can choose one of them as our target\n",
    "    df['visit'] = dataset.target\n",
    "    print(df.info())\n",
    "    print(df.isna().sum())\n",
    "    return df\n",
    "\n",
    "df = load_hillstrom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment\n",
       "Womens E-Mail    21387\n",
       "Mens E-Mail      21307\n",
       "No E-Mail        21306\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The treatment\n",
    "df['segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment\n",
       "1    0.500012\n",
       "0    0.499988\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just use men's email first and create a treatment variable to 1/0 the treatment/control\n",
    "df = df.loc[df['segment'].isin(['Mens E-Mail','No E-Mail'])]\n",
    "df['treatment'] = df['segment'].map({'Mens E-Mail':1,'No E-Mail':0})\n",
    "df['treatment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    36457\n",
       "1     6156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset has visit, conversion, and revenue as the target variables, we are going to use visit as the target variable\n",
    "df['target'] = df['visit'].copy()\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mens\n",
       "1    23526\n",
       "0    19087\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customer purchased mens merchandise in the past year\n",
    "df['mens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womens\n",
       "1    23417\n",
       "0    19196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customer purchased womens merchandise in the past year\n",
    "df['womens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mens  womens\n",
       "0     1         19087\n",
       "1     0         19196\n",
       "      1          4330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only a few customers purchased from both mens and womens merch in the past year\n",
    "df.groupby(['mens','womens']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "history_segment\n",
       "1) $0 - $100        15336\n",
       "2) $100 - $200       9527\n",
       "3) $200 - $350       8134\n",
       "4) $350 - $500       4221\n",
       "5) $500 - $750       3249\n",
       "6) $750 - $1,000     1266\n",
       "7) $1,000 +           880\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segments for TTM spend\n",
    "df['history_segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42613.000000\n",
       "mean       241.859315\n",
       "std        256.574723\n",
       "min         29.990000\n",
       "25%         64.500000\n",
       "50%        157.000000\n",
       "75%        325.210000\n",
       "max       3345.930000\n",
       "Name: history, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual TTM spend\n",
    "df['history'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recency\n",
       "1     5934\n",
       "2     5074\n",
       "10    5022\n",
       "9     4330\n",
       "3     3899\n",
       "4     3406\n",
       "6     3048\n",
       "5     2985\n",
       "7     2720\n",
       "8     2337\n",
       "11    2316\n",
       "12    1542\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Months since last purchase\n",
    "df['recency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newbie\n",
       "1    21381\n",
       "0    21232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New custome in past year\n",
    "df['newbie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel\n",
       "Web             18863\n",
       "Phone           18567\n",
       "Multichannel     5183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TTM purchase channels - must be an old dataset given the phone count\n",
    "df['channel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code\n",
       "Surburban    19126\n",
       "Urban        17105\n",
       "Rural         6382\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifies urban rural and suburban\n",
    "df['zip_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the zip code and channel variables\n",
    "df = pd.get_dummies(df, columns=['zip_code'], drop_first=True, dtype=int)  # Encode categorical variable\n",
    "df = pd.get_dummies(df, columns=['channel'], drop_first=True, dtype=int)  # Encode categorical variable\n",
    "df = df.drop(columns=['history_segment','segment','visit']) # Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>newbie</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "      <th>zip_code_Surburban</th>\n",
       "      <th>zip_code_Urban</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>channel_Web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>675.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>675.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>101.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>241.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recency  history  mens  womens  newbie  treatment  target  \\\n",
       "1         6   329.08     1       1       1          0       0   \n",
       "3         9   675.83     1       0       1          1       0   \n",
       "8         9   675.07     1       1       1          1       0   \n",
       "13        2   101.64     0       1       0          1       1   \n",
       "14        4   241.42     0       1       1          0       0   \n",
       "\n",
       "    zip_code_Surburban  zip_code_Urban  channel_Phone  channel_Web  \n",
       "1                    0               0              0            1  \n",
       "3                    0               0              0            1  \n",
       "8                    0               0              1            0  \n",
       "13                   0               1              0            1  \n",
       "14                   0               0              0            0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One grand view of our final dataset! Looks ready for modeling.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>newbie</th>\n",
       "      <th>target</th>\n",
       "      <th>zip_code_Surburban</th>\n",
       "      <th>zip_code_Urban</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>channel_Web</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.749695</td>\n",
       "      <td>240.882653</td>\n",
       "      <td>0.553224</td>\n",
       "      <td>0.547639</td>\n",
       "      <td>0.501971</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.400920</td>\n",
       "      <td>0.437764</td>\n",
       "      <td>0.439923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.773642</td>\n",
       "      <td>242.835931</td>\n",
       "      <td>0.550946</td>\n",
       "      <td>0.551415</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>0.182757</td>\n",
       "      <td>0.445910</td>\n",
       "      <td>0.401887</td>\n",
       "      <td>0.433660</td>\n",
       "      <td>0.445394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            recency     history      mens    womens    newbie    target  \\\n",
       "treatment                                                                 \n",
       "0          5.749695  240.882653  0.553224  0.547639  0.501971  0.106167   \n",
       "1          5.773642  242.835931  0.550946  0.551415  0.501525  0.182757   \n",
       "\n",
       "           zip_code_Surburban  zip_code_Urban  channel_Phone  channel_Web  \n",
       "treatment                                                                  \n",
       "0                    0.451751        0.400920       0.437764     0.439923  \n",
       "1                    0.445910        0.401887       0.433660     0.445394  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It appears everything is just about equal in terms of the treatment group and the control group for feature means, except the target which is ok\n",
    "df.groupby('treatment').mean()\n",
    "\n",
    "# Even if it wasn't, we could still run the model using the covariates as features, but would need to adjust for the imbalance in the treatment groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test\n",
    "def split_data(df):\n",
    "    X = df.drop(columns=['treatment', 'target'])\n",
    "    y = df['target']\n",
    "    treatment = df['treatment']\n",
    "    return train_test_split(X, y, treatment, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test, t_train, t_test = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Two-Model and Single-Model Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Optimization with Optuna\n",
    "def optimize_model(trial, X, y, model_type):\n",
    "    # Set the hyperparameters to optimize and the ranges for xgboost\n",
    "    if model_type == 'xgboost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        }\n",
    "        model = XGBClassifier(**params, eval_metric='logloss')\n",
    "        # Even though the eval metric for xgboost is logloss, we are evaluating the hyperparameters on maximizing AUC\n",
    "    # Set the hyperparameters to optimize the ranges for random forest\n",
    "    elif model_type == 'random_forest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_float('max_features', 0.6, 1.0),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='roc_auc')\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna for Both Models\n",
    "def run_optuna(X, y, model_type, model_seg, n_trials=50):\n",
    "    # Create a study object to maximize the AUC\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    # optimize the study based on the input parameters\n",
    "    study.optimize(lambda trial: optimize_model(trial, X, y, model_type), n_trials=n_trials)\n",
    "    print(f\"Best parameters for {model_type} for {model_seg}: {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, params, model_type, model_seg):\n",
    "    # We'll look at xgboost and random forest, this is to train the final mdoel after optuna works it's magic\n",
    "    if model_type == 'xgboost':\n",
    "        model = XGBClassifier(**params,  eval_metric='logloss')\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    # Fit the model and predict probabilities on the test dataset\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Grab the AUC & LogLoss metrics for the best model\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    logloss = log_loss(y_test, y_pred)\n",
    "    print(f\"{model_type} AUC for {model_seg}: {auc:.4f}\\n{model_type} Log Loss for {model_seg}: {logloss:.4f}\")\n",
    "    return model,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize and Train Separate Models for Two-Model Approach\n",
    "def two_model_approach_with_optuna(X_train, X_test, y_train, y_test, t_train):\n",
    "    \n",
    "    # Use function run_optuna to optimize the treatment model for xgboost and random forest adn return the optimal hyperparameters\n",
    "\n",
    "    # Optimize treatment model for xgboost and random forest\n",
    "    X_treatment = X_train[t_train == 1]\n",
    "    y_treatment = y_train[t_train == 1]\n",
    "    params_treatment_xgboost = run_optuna(X_treatment, y_treatment, 'xgboost','treatment')\n",
    "    params_treatment_randomforest = run_optuna(X_treatment, y_treatment, 'random_forest','treatment')\n",
    "\n",
    "    # Optimize control model for xgboost and random forest\n",
    "    X_control = X_train[t_train == 0]\n",
    "    y_control = y_train[t_train == 0]\n",
    "    params_control_xgboost = run_optuna(X_control, y_control, 'xgboost','control')\n",
    "    params_control_randomforest = run_optuna(X_control, y_control, 'random_forest','control')\n",
    "\n",
    "\n",
    "    # Optimize single model for xgboost and random forest\n",
    "    X_single_train = X_train.copy()\n",
    "    X_single_train['treatment'] = t_train\n",
    "    X_single_test_1 = X_test.copy()\n",
    "    X_single_test_1['treatment'] = 1\n",
    "    X_single_test_0 = X_test.copy()\n",
    "    X_single_test_0['treatment'] = 0\n",
    "    params_single_xgboost = run_optuna(X_single_train, y_train, 'xgboost','single')\n",
    "    params_single_randomforest = run_optuna(X_single_train, y_train, 'random_forest','single')\n",
    "\n",
    "    # Train final models using function train_and_evaluate\n",
    "    model_treatment_xgboost,preds_treatment_xgboost = train_and_evaluate(X_treatment, X_test, y_treatment, y_test, params_treatment_xgboost, 'xgboost','treatment')\n",
    "    model_treatment_randomforest,preds_treatment_randomforest = train_and_evaluate(X_treatment, X_test, y_treatment, y_test, params_treatment_randomforest, 'random_forest','treatment')\n",
    "    model_control_xgboost,preds_control_xgboost = train_and_evaluate(X_control, X_test, y_control, y_test, params_control_xgboost, 'xgboost','control')\n",
    "    model_control_randomforest,preds_control_randomforest = train_and_evaluate(X_control, X_test, y_control, y_test, params_control_randomforest, 'random_forest','control')\n",
    "    model_single_1_xgboost,preds_single_1_xgboost = train_and_evaluate(X_single_train, X_single_test_1, y_train, y_test, params_single_xgboost, 'xgboost','single_1')\n",
    "    model_single_1_randomforest,preds_single_1_randomforest = train_and_evaluate(X_single_train, X_single_test_1, y_train, y_test, params_single_randomforest, 'random_forest','single_1')\n",
    "    model_single_0_xgboost,preds_single_0_xgboost = train_and_evaluate(X_single_train, X_single_test_0, y_train, y_test, params_single_xgboost, 'xgboost','single_0')\n",
    "    model_single_0_randomforest,preds_single_0_randomforest = train_and_evaluate(X_single_train, X_single_test_0, y_train, y_test, params_single_randomforest, 'random_forest','single_0')\n",
    "\n",
    "    return model_treatment_xgboost, preds_treatment_xgboost, model_treatment_randomforest, preds_treatment_randomforest, model_control_xgboost, preds_control_xgboost, model_control_randomforest, preds_control_randomforest, model_single_1_xgboost, preds_single_1_xgboost, model_single_1_randomforest, preds_single_1_randomforest, model_single_0_xgboost, preds_single_0_xgboost, model_single_0_randomforest, preds_single_0_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-23 14:32:09,074] A new study created in memory with name: no-name-d84b42d9-ea7f-425f-b98a-6e3fe6b461b5\n",
      "[I 2024-12-23 14:32:09,475] Trial 0 finished with value: 0.6118543375745146 and parameters: {'n_estimators': 227, 'max_depth': 4, 'learning_rate': 0.011102732427673404, 'subsample': 0.6359825674692446, 'colsample_bytree': 0.871518162874717, 'gamma': 3.7131452388142305}. Best is trial 0 with value: 0.6118543375745146.\n",
      "[I 2024-12-23 14:32:09,818] Trial 1 finished with value: 0.6143241628081094 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.026785674478213208, 'subsample': 0.7329636811500612, 'colsample_bytree': 0.6155214126819654, 'gamma': 4.657185058913145}. Best is trial 1 with value: 0.6143241628081094.\n",
      "[I 2024-12-23 14:32:10,104] Trial 2 finished with value: 0.6124102102848042 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.013050200513450376, 'subsample': 0.7391253840695207, 'colsample_bytree': 0.6434284711150586, 'gamma': 3.5767055405314774}. Best is trial 1 with value: 0.6143241628081094.\n",
      "[I 2024-12-23 14:32:10,397] Trial 3 finished with value: 0.6081893490836868 and parameters: {'n_estimators': 235, 'max_depth': 3, 'learning_rate': 0.19433731853247682, 'subsample': 0.8387952917277078, 'colsample_bytree': 0.7841661799505559, 'gamma': 1.3095493009475927}. Best is trial 1 with value: 0.6143241628081094.\n",
      "[W 2024-12-23 14:32:10,402] Trial 4 failed with parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.01815501046579285, 'subsample': 0.9395716389157067, 'colsample_bytree': 0.839970867383853, 'gamma': 4.9500823269539165} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_25112\\4247110055.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: optimize_model(trial, X, y, model_type), n_trials=n_trials)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_25112\\1502590024.py\", line 28, in optimize_model\n",
      "    scores = cross_val_score(model, X, y, cv=3, scoring='roc_auc')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 353, in cross_validate\n",
      "    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 2643, in check_cv\n",
      "    and (type_of_target(y, input_name=\"y\") in (\"binary\", \"multiclass\"))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 406, in type_of_target\n",
      "    if xp.unique_values(y).shape[0] > 2 or (y.ndim == 2 and len(first_row_or_val) > 1):\n",
      "       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 407, in unique_values\n",
      "    return numpy.unique(x)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 276, in unique\n",
      "    return _unpack_tuple(ret)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 125, in _unpack_tuple\n",
      "    def _unpack_tuple(x):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2024-12-23 14:32:10,414] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Execute the Two-Model Approach with Optuna usng function \"two_model_approach_with_optuna\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_treatment_xgboost, preds_treatment_xgboost, model_treatment_randomforest, preds_treatment_randomforest, model_control_xgboost, preds_control_xgboost, model_control_randomforest, preds_control_randomforest, model_single_xgboost, preds_single_xgboost, model_single_randomforest, preds_single_randomforest \u001b[38;5;241m=\u001b[39m \u001b[43mtwo_model_approach_with_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 9\u001b[0m, in \u001b[0;36mtwo_model_approach_with_optuna\u001b[1;34m(X_train, X_test, y_train, y_test, t_train)\u001b[0m\n\u001b[0;32m      7\u001b[0m X_treatment \u001b[38;5;241m=\u001b[39m X_train[t_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m y_treatment \u001b[38;5;241m=\u001b[39m y_train[t_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m params_treatment_xgboost \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_treatment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_treatment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreatment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m params_treatment_randomforest \u001b[38;5;241m=\u001b[39m run_optuna(X_treatment, y_treatment, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Optimize control model for xgboost and random forest\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m, in \u001b[0;36mrun_optuna\u001b[1;34m(X, y, model_type, model_seg, n_trials)\u001b[0m\n\u001b[0;32m      4\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# optimize the study based on the input parameters\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_seg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m, in \u001b[0;36mrun_optuna.<locals>.<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      4\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# optimize the study based on the input parameters\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39mn_trials)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_seg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "Cell \u001b[1;32mIn[42], line 28\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m(trial, X, y, model_type)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores)\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:353\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    349\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_params_groups_deprecation(fit_params, params, groups)\n\u001b[0;32m    351\u001b[0m X, y \u001b[38;5;241m=\u001b[39m indexable(X, y)\n\u001b[1;32m--> 353\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n\u001b[0;32m    356\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m scoring\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2643\u001b[0m, in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2638\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m cv\n\u001b[0;32m   2639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cv, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2641\u001b[0m         classifier\n\u001b[0;32m   2642\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 2643\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   2644\u001b[0m     ):\n\u001b[0;32m   2645\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m StratifiedKFold(cv)\n\u001b[0;32m   2646\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:406\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(first_row_or_val):\n\u001b[0;32m    405\u001b[0m     first_row_or_val \u001b[38;5;241m=\u001b[39m first_row_or_val\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row_or_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:407\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:276\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unpack_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:125\u001b[0m, in \u001b[0;36m_unpack_tuple\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    121\u001b[0m     np\u001b[38;5;241m.\u001b[39msubtract(ary[\u001b[38;5;241m1\u001b[39m:], ary[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], result[l_begin:l_begin \u001b[38;5;241m+\u001b[39m l_diff])\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unpack_tuple\u001b[39m(x):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Unpacks one-element tuples for use as return values \"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Execute the Two-Model Approach with Optuna usng function \"two_model_approach_with_optuna\"\n",
    "model_treatment_xgboost, preds_treatment_xgboost, model_treatment_randomforest, preds_treatment_randomforest, model_control_xgboost, preds_control_xgboost, model_control_randomforest, preds_control_randomforest, model_single_1_xgboost, preds_single_1_xgboost, model_single_1_randomforest, preds_single_1_randomforest, model_single_0_xgboost, preds_single_0_xgboost, model_single_0_randomforest, preds_single_0_randomforest = two_model_approach_with_optuna(X_train, X_test, y_train, y_test, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uplift scores\n",
    "def create_uplift_scores(preds_treatment_xgboost,\n",
    "                        preds_control_xgboost,\n",
    "                        preds_treatment_randomforest,\n",
    "                        preds_control_randomforest,\n",
    "                        preds_single_1_xgboost,\n",
    "                        preds_single_1_randomforest,\n",
    "                        preds_single_0_xgboost,\n",
    "                        preds_single_0_randomforest):\n",
    "\n",
    "    uplift_two_model_rf = preds_treatment_randomforest - preds_control_randomforest\n",
    "\n",
    "    uplift_two_model_xg = preds_treatment_xgboost - preds_control_xgboost\n",
    "\n",
    "    uplift_single_model_xg = preds_single_1_xgboost - preds_single_0_xgboost\n",
    "    \n",
    "    uplift_single_model_rf = preds_single_1_randomforest - preds_single_0_randomforest\n",
    "    \n",
    "    return uplift_two_model_rf, uplift_two_model_xg, uplift_single_model_xg, uplift_single_model_rf\n",
    "\n",
    "uplift_two_model_rf, uplift_two_model_xg, uplift_single_model_xg, uplift_single_model_rf = create_uplift_scores(preds_treatment_xgboost,\n",
    "                                                                                                                preds_control_xgboost,\n",
    "                                                                                                                preds_treatment_randomforest,\n",
    "                                                                                                                preds_control_randomforest,\n",
    "                                                                                                                preds_single_1_xgboost,\n",
    "                                                                                                                preds_single_1_randomforest,\n",
    "                                                                                                                preds_single_0_xgboost,\n",
    "                                                                                                                preds_single_0_randomforest\n",
    "                                                                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with test results\n",
    "results_df = pd.DataFrame({\n",
    "    'y_true': y_test,               # Actual outcomes\n",
    "    'treatment': t_test,            # Treatment indicators\n",
    "    'uplift_rf': uplift_two_model_rf,         # Uplift predictions from Random Forest\n",
    "    'uplift_xgb': uplift_two_model_xg        # Uplift predictions from XGBoost\n",
    "})\n",
    "results_df['uplift_diff'] = results_df['uplift_rf'] - results_df['uplift_xgb']\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Two-Model Approaches and Single-Model Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular Comparison of Qini Scores\n",
    "qini_two_model_rf = qini_auc_score(y_test, uplift_two_model_rf, t_test)\n",
    "qini_two_model_xg = qini_auc_score(y_test, uplift_two_model_xg, t_test)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Two-Model RF', 'Two-Model XG'],\n",
    "    'Qini Score': [qini_two_model_rf, qini_two_model_xg]\n",
    "})\n",
    "print(\"\\n### Qini Score Comparison ###\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Qini Evaluation\n",
    "def evaluate_qini(uplift, y_test, t_test, model_name):\n",
    "    qini = qini_auc_score(y_test, uplift, t_test)\n",
    "\n",
    "    uplift_k = uplift_at_k(y_test, uplift, t_test, strategy='overall', k=k)\n",
    "\n",
    "    print(f\"{model_name} Qini Score: {qini:.4f}\")\n",
    "\n",
    "    # Plot the Qini Curve\n",
    "    plt.plot(k_values, uplift_k, label=f'{model_name} Model')\n",
    "    plt.plot([0, 1], [0, max(uplift_cumulative)], '--', label='Random')\n",
    "    plt.xlabel('Proportion of Population Targeted')\n",
    "    plt.ylabel('Cumulative Uplift')\n",
    "    plt.title(f'Qini Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Compare Two-Model and S-Learner\n",
    "print(\"### Two-Model Random Forest Approach Evaluation ###\")\n",
    "evaluate_qini(uplift_two_model_rf, y_test, t_test, \"Two-Model Random Forest\")\n",
    "\n",
    "print(\"### Two-Model XGBoost Approach Evaluatio ###\")\n",
    "evaluate_qini(uplift_two_model_xg, y_test, t_test, \"Two-Model XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uplift_metrics(df,uplift, n_groups=5):\n",
    "    \"\"\"\n",
    "    Calculate common uplift model evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: array-like, actual outcome (visits)\n",
    "    treatment: array-like, treatment indicator (0/1)\n",
    "    uplift_scores: array-like, predicted uplift scores\n",
    "    n_groups: int, number of groups for AUUC calculation\n",
    "    \n",
    "    Returns:\n",
    "    dict with uplift metrics\n",
    "    \"\"\"\n",
    "    # Sort by uplift scores\n",
    "    df = df.sort_values(by=uplift, ascending=False)\n",
    "    y_true = df['y_true'].values\n",
    "    treatment = df['treatment'].values\n",
    "    \n",
    "    # Calculate cumulative gains\n",
    "    n_samples = len(y_true)\n",
    "    group_size = n_samples // n_groups\n",
    "    \n",
    "    gains = []\n",
    "    for i in range(n_groups):\n",
    "        start_idx = i * group_size\n",
    "        end_idx = (i + 1) * group_size if i < n_groups - 1 else n_samples\n",
    "        \n",
    "        group_treat = treatment[start_idx:end_idx]\n",
    "        group_outcome = y_true[start_idx:end_idx]\n",
    "        \n",
    "        # Calculate treatment and control response rates\n",
    "        treat_rate = np.mean(group_outcome[group_treat == 1])\n",
    "        ctrl_rate = np.mean(group_outcome[group_treat == 0])\n",
    "        \n",
    "        # Calculate uplift\n",
    "        uplift = treat_rate - ctrl_rate\n",
    "        gains.append(uplift)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'AUUC': np.trapz(gains) / len(gains),  # Area Under the Uplift Curve\n",
    "        'Qini': np.sum(gains),  # Qini coefficient\n",
    "        'top_group_uplift': gains[0],  # Uplift in highest scored group\n",
    "        'uplift_by_group': gains\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_metrics = calculate_uplift_metrics(\n",
    "   df=results_df,\n",
    "   uplift='uplift_xgb'\n",
    "   )\n",
    "\n",
    "rf_metrics = calculate_uplift_metrics(\n",
    "   df=results_df,\n",
    "   uplift='uplift_rf'\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_metrics = calculate_uplift_metrics(\n",
    "   df=results_df,\n",
    "   uplift='uplift_xgb'\n",
    "   )\n",
    "\n",
    "rf_metrics = calculate_uplift_metrics(\n",
    "   df=results_df,\n",
    "   uplift='uplift_rf'\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Two-Model Approach Evaluation ###\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'uplift_two_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[47], line 26\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Compare Two-Model and S-Learner\u001b[39;00m\n",
      "\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Two-Model Approach Evaluation ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m---> 26\u001b[0m evaluate_qini(\u001b[43muplift_two_model\u001b[49m, y_test, t_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwo-Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### S-Learner Evaluation ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     29\u001b[0m evaluate_qini(uplift_s_learner, y_test, t_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS-Learner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'uplift_two_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Enhanced Qini Evaluation\n",
    "def evaluate_qini(uplift, y_test, t_test, model_name):\n",
    "    qini = qini_auc_score(y_test, uplift, t_test)\n",
    "\n",
    "    # Use a loop to calculate uplift at different percentages\n",
    "    k_values = [i / 100 for i in range(1, 100)]  # Generate k as float values from 0.01 to 1\n",
    "    uplift_cumulative = []\n",
    "\n",
    "    for k in k_values:\n",
    "        uplift_k = uplift_at_k(y_test, uplift, t_test, strategy='overall', k=k)\n",
    "        uplift_cumulative.append(uplift_k)\n",
    "\n",
    "    print(f\"{model_name} Qini Score: {qini:.4f}\")\n",
    "\n",
    "    # Plot the Qini Curve\n",
    "    plt.plot(k_values, uplift_cumulative, label=f'{model_name} Model')\n",
    "    plt.plot([0, 1], [0, max(uplift_cumulative)], '--', label='Random')\n",
    "    plt.xlabel('Proportion of Population Targeted')\n",
    "    plt.ylabel('Cumulative Uplift')\n",
    "    plt.title(f'Qini Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Compare Two-Model and S-Learner\n",
    "print(\"### Two-Model Approach Evaluation ###\")\n",
    "evaluate_qini(uplift_two_model, y_test, t_test, \"Two-Model\")\n",
    "\n",
    "print(\"### S-Learner Evaluation ###\")\n",
    "evaluate_qini(uplift_s_learner, y_test, t_test, \"S-Learner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Tabular Comparison of Qini Scores\n",
    "qini_two_model = qini_auc_score(y_test, uplift_two_model, t_test)\n",
    "qini_s_learner = qini_auc_score(y_test, uplift_s_learner, t_test)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Two-Model', 'S-Learner'],\n",
    "    'Qini Score': [qini_two_model, qini_s_learner]\n",
    "})\n",
    "print(\"\\n### Qini Score Comparison ###\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
