{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal ML, Uplift Modeling Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklift.metrics import uplift_at_k,qini_auc_score\n",
    "from sklift.datasets import fetch_hillstrom\n",
    "from xgboost import XGBClassifier\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64000 entries, 0 to 63999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   recency          64000 non-null  int64  \n",
      " 1   history_segment  64000 non-null  object \n",
      " 2   history          64000 non-null  float64\n",
      " 3   mens             64000 non-null  int64  \n",
      " 4   womens           64000 non-null  int64  \n",
      " 5   zip_code         64000 non-null  object \n",
      " 6   newbie           64000 non-null  int64  \n",
      " 7   channel          64000 non-null  object \n",
      " 8   segment          64000 non-null  object \n",
      " 9   visit            64000 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(4)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "recency            0\n",
      "history_segment    0\n",
      "history            0\n",
      "mens               0\n",
      "womens             0\n",
      "zip_code           0\n",
      "newbie             0\n",
      "channel            0\n",
      "segment            0\n",
      "visit              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Hillstrom dataset\n",
    "def load_hillstrom():\n",
    "    dataset = fetch_hillstrom()\n",
    "    df = dataset.data\n",
    "    df['segment'] = dataset.treatment\n",
    "    df['visit'] = dataset.target\n",
    "    print(df.info())\n",
    "    print(df.isna().sum())\n",
    "    return df\n",
    "\n",
    "df = load_hillstrom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment\n",
       "Womens E-Mail    21387\n",
       "Mens E-Mail      21307\n",
       "No E-Mail        21306\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The treatment\n",
    "df['segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment\n",
       "1    0.500012\n",
       "0    0.499988\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There appears to be 2 segments, let's just use the mens email to start\n",
    "df = df.loc[df['segment'].isin(['Mens E-Mail','No E-Mail'])]\n",
    "df['treatment'] = df['segment'].map({'Mens E-Mail':1,'No E-Mail':0})\n",
    "df['treatment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    36457\n",
       "1     6156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset has visit, conversion, and revenue as the target variables, we are going to use visit as the target variable\n",
    "df['target'] = df['visit'].copy()\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mens\n",
       "1    23526\n",
       "0    19087\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womens\n",
       "1    23417\n",
       "0    19196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['womens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "history_segment\n",
       "1) $0 - $100        15336\n",
       "2) $100 - $200       9527\n",
       "3) $200 - $350       8134\n",
       "4) $350 - $500       4221\n",
       "5) $500 - $750       3249\n",
       "6) $750 - $1,000     1266\n",
       "7) $1,000 +           880\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['history_segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42613.000000\n",
       "mean       241.859315\n",
       "std        256.574723\n",
       "min         29.990000\n",
       "25%         64.500000\n",
       "50%        157.000000\n",
       "75%        325.210000\n",
       "max       3345.930000\n",
       "Name: history, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['history'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recency\n",
       "1     5934\n",
       "2     5074\n",
       "10    5022\n",
       "9     4330\n",
       "3     3899\n",
       "4     3406\n",
       "6     3048\n",
       "5     2985\n",
       "7     2720\n",
       "8     2337\n",
       "11    2316\n",
       "12    1542\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['recency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newbie\n",
       "1    21381\n",
       "0    21232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['newbie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel\n",
       "Web             18863\n",
       "Phone           18567\n",
       "Multichannel     5183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['channel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code\n",
       "Surburban    19126\n",
       "Urban        17105\n",
       "Rural         6382\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['zip_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['zip_code'], drop_first=True, dtype=int)  # Encode categorical variable\n",
    "df = pd.get_dummies(df, columns=['channel'], drop_first=True, dtype=int)  # Encode categorical variable\n",
    "df = df.drop(columns=['history_segment','segment','visit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>newbie</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "      <th>zip_code_Surburban</th>\n",
       "      <th>zip_code_Urban</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>channel_Web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>675.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>675.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>101.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>241.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recency  history  mens  womens  newbie  treatment  target  \\\n",
       "1         6   329.08     1       1       1          0       0   \n",
       "3         9   675.83     1       0       1          1       0   \n",
       "8         9   675.07     1       1       1          1       0   \n",
       "13        2   101.64     0       1       0          1       1   \n",
       "14        4   241.42     0       1       1          0       0   \n",
       "\n",
       "    zip_code_Surburban  zip_code_Urban  channel_Phone  channel_Web  \n",
       "1                    0               0              0            1  \n",
       "3                    0               0              0            1  \n",
       "8                    0               0              1            0  \n",
       "13                   0               1              0            1  \n",
       "14                   0               0              0            0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>newbie</th>\n",
       "      <th>target</th>\n",
       "      <th>zip_code_Surburban</th>\n",
       "      <th>zip_code_Urban</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>channel_Web</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.749695</td>\n",
       "      <td>240.882653</td>\n",
       "      <td>0.553224</td>\n",
       "      <td>0.547639</td>\n",
       "      <td>0.501971</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.400920</td>\n",
       "      <td>0.437764</td>\n",
       "      <td>0.439923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.773642</td>\n",
       "      <td>242.835931</td>\n",
       "      <td>0.550946</td>\n",
       "      <td>0.551415</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>0.182757</td>\n",
       "      <td>0.445910</td>\n",
       "      <td>0.401887</td>\n",
       "      <td>0.433660</td>\n",
       "      <td>0.445394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            recency     history      mens    womens    newbie    target  \\\n",
       "treatment                                                                 \n",
       "0          5.749695  240.882653  0.553224  0.547639  0.501971  0.106167   \n",
       "1          5.773642  242.835931  0.550946  0.551415  0.501525  0.182757   \n",
       "\n",
       "           zip_code_Surburban  zip_code_Urban  channel_Phone  channel_Web  \n",
       "treatment                                                                  \n",
       "0                    0.451751        0.400920       0.437764     0.439923  \n",
       "1                    0.445910        0.401887       0.433660     0.445394  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It appears everything is just about equal in terms of the treatment group and the control group for feature means, except the target which is ok\n",
    "df.groupby('treatment').mean()\n",
    "\n",
    "# Even if it wasn't, we could still run the model using the covariates as features, but would need to adjust for the imbalance in the treatment groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split data into train/test\n",
    "def split_data(df):\n",
    "    X = df.drop(columns=['treatment', 'target'])\n",
    "    y = df['target']\n",
    "    treatment = df['treatment']\n",
    "    return train_test_split(X, y, treatment, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test, t_train, t_test = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Two Model Approach, the traditional uplift model approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1st Model, Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Optimization with Optuna\n",
    "def optimize_model(trial, X, y, model_type):\n",
    "    if model_type == 'xgboost':\n",
    "        # Set the hyperparameters to optimize and the ranges\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        }\n",
    "        model = XGBClassifier(**params, eval_metric='logloss')\n",
    "    elif model_type == 'random_forest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_float('max_features', 0.6, 1.0),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='roc_auc')\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run Optuna for Both Models\n",
    "def run_optuna(X, y, model_type, n_trials=50):\n",
    "    # Create a study object to maximize the AUC\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    # optimize the study based on the input parameters\n",
    "    study.optimize(lambda trial: optimize_model(trial, X, y, model_type), n_trials=n_trials)\n",
    "    print(f\"Best parameters for {model_type}: {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train and Evaluate Models\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, params, model_type):\n",
    "    if model_type == 'xgboost':\n",
    "        model = XGBClassifier(**params,  eval_metric='logloss')\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    logloss = log_loss(y_test, y_pred)\n",
    "    print(f\"{model_type} AUC: {auc:.4f}, Log Loss: {logloss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Optimize and Train Separate Models for Two-Model Approach\n",
    "def two_model_approach_with_optuna(X_train, X_test, y_train, y_test, t_train):\n",
    "    \n",
    "    # Use function run_optuna to optimize the treatment model for xgboost and random forest adn return the optimal hyperparameters\n",
    "\n",
    "    # Optimize treatment model for xgboost and random forest\n",
    "    X_treatment = X_train[t_train == 1]\n",
    "    y_treatment = y_train[t_train == 1]\n",
    "    params_treatment_xgboost = run_optuna(X_treatment, y_treatment, 'xgboost')\n",
    "    params_treatment_randomforest = run_optuna(X_treatment, y_treatment, 'random_forest')\n",
    "\n",
    "    # Optimize control model for xgboost and random forest\n",
    "    X_control = X_train[t_train == 0]\n",
    "    y_control = y_train[t_train == 0]\n",
    "    params_control_xgboost = run_optuna(X_control, y_control, 'xgboost')\n",
    "    params_control_randomforest = run_optuna(X_control, y_control, 'random_forest')\n",
    "\n",
    "    # Train final models using function train_and_evaluate\n",
    "    model_treatment_xgboost = train_and_evaluate(X_treatment, X_test, y_treatment, y_test, params_treatment_xgboost, 'xgboost')\n",
    "    model_treatment_randomforest = train_and_evaluate(X_treatment, X_test, y_treatment, y_test, params_treatment_randomforest, 'random_forest')\n",
    "    model_control_xgboost = train_and_evaluate(X_control, X_test, y_control, y_test, params_control_xgboost, 'xgboost')\n",
    "    model_control_randomforest = train_and_evaluate(X_control, X_test, y_control, y_test, params_control_randomforest, 'random_forest')\n",
    "\n",
    "    return model_treatment_xgboost, model_control_randomforest, model_treatment_randomforest, model_control_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 20:43:10,616] A new study created in memory with name: no-name-3ec8e898-dd10-469f-aba3-5bb99b633e6c\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:10,935] Trial 0 finished with value: 0.61238470912025 and parameters: {'n_estimators': 207, 'max_depth': 4, 'learning_rate': 0.02047579304694242, 'subsample': 0.8860735617267557, 'colsample_bytree': 0.9328120967876155, 'gamma': 3.395245184765317}. Best is trial 0 with value: 0.61238470912025.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:11,240] Trial 1 finished with value: 0.597117359244708 and parameters: {'n_estimators': 92, 'max_depth': 9, 'learning_rate': 0.039542878137343467, 'subsample': 0.8592977509800693, 'colsample_bytree': 0.7643553675732279, 'gamma': 0.7907659937576988}. Best is trial 0 with value: 0.61238470912025.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:11,542] Trial 2 finished with value: 0.6124487699864692 and parameters: {'n_estimators': 288, 'max_depth': 3, 'learning_rate': 0.03829723777474196, 'subsample': 0.9795270194196607, 'colsample_bytree': 0.8120526378596631, 'gamma': 3.8492950761633087}. Best is trial 2 with value: 0.6124487699864692.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:12,008] Trial 3 finished with value: 0.6096963323584516 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.02819590550673673, 'subsample': 0.9690292542960117, 'colsample_bytree': 0.7676060736362404, 'gamma': 0.44600093554927}. Best is trial 2 with value: 0.6124487699864692.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:12,377] Trial 4 finished with value: 0.6092168452992373 and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.010181112991355303, 'subsample': 0.9235953107872326, 'colsample_bytree': 0.9753850165250387, 'gamma': 3.9347669192926555}. Best is trial 2 with value: 0.6124487699864692.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:12,755] Trial 5 finished with value: 0.604946603865447 and parameters: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.03763871244882145, 'subsample': 0.6966498593948522, 'colsample_bytree': 0.990071425272803, 'gamma': 2.186939913418863}. Best is trial 2 with value: 0.6124487699864692.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:12,971] Trial 6 finished with value: 0.6043240446842254 and parameters: {'n_estimators': 123, 'max_depth': 7, 'learning_rate': 0.10345203129623483, 'subsample': 0.7880043945173446, 'colsample_bytree': 0.8148869448306052, 'gamma': 1.8082765529483886}. Best is trial 2 with value: 0.6124487699864692.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:13,290] Trial 7 finished with value: 0.6142298773298673 and parameters: {'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.03100679311016375, 'subsample': 0.7308736640972927, 'colsample_bytree': 0.6743110166091674, 'gamma': 4.4611433074983}. Best is trial 7 with value: 0.6142298773298673.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:13,740] Trial 8 finished with value: 0.6011429956985045 and parameters: {'n_estimators': 153, 'max_depth': 7, 'learning_rate': 0.01418750577814298, 'subsample': 0.635922870409532, 'colsample_bytree': 0.9996985848192707, 'gamma': 1.3933697335387296}. Best is trial 7 with value: 0.6142298773298673.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:14,127] Trial 9 finished with value: 0.6016880013514032 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.05838499682818762, 'subsample': 0.9315631096151006, 'colsample_bytree': 0.7229485030560281, 'gamma': 0.7955343157749739}. Best is trial 7 with value: 0.6142298773298673.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:14,409] Trial 10 finished with value: 0.6165533020469635 and parameters: {'n_estimators': 211, 'max_depth': 9, 'learning_rate': 0.2817679174845985, 'subsample': 0.7596020468524364, 'colsample_bytree': 0.6168710764811075, 'gamma': 4.722790898704698}. Best is trial 10 with value: 0.6165533020469635.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:14,703] Trial 11 finished with value: 0.6172965072257316 and parameters: {'n_estimators': 208, 'max_depth': 10, 'learning_rate': 0.19969570808437617, 'subsample': 0.7480345228273033, 'colsample_bytree': 0.6007327056030227, 'gamma': 4.974775486769139}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:14,956] Trial 12 finished with value: 0.6141408280923638 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.257533570691626, 'subsample': 0.7928396646552351, 'colsample_bytree': 0.6054649880634501, 'gamma': 4.751917208190349}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:15,224] Trial 13 finished with value: 0.6062969253682673 and parameters: {'n_estimators': 196, 'max_depth': 9, 'learning_rate': 0.2992140108942351, 'subsample': 0.7205315073182987, 'colsample_bytree': 0.608468544434086, 'gamma': 2.874089497561265}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:15,368] Trial 14 finished with value: 0.6133897911157445 and parameters: {'n_estimators': 51, 'max_depth': 10, 'learning_rate': 0.1580352788131236, 'subsample': 0.619228830437309, 'colsample_bytree': 0.6803657446106234, 'gamma': 4.9694000681121935}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:15,638] Trial 15 finished with value: 0.6151180549374332 and parameters: {'n_estimators': 226, 'max_depth': 9, 'learning_rate': 0.15224373149023804, 'subsample': 0.8327047825946496, 'colsample_bytree': 0.6589507220569828, 'gamma': 4.250120061904769}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:15,921] Trial 16 finished with value: 0.6107180827365468 and parameters: {'n_estimators': 166, 'max_depth': 8, 'learning_rate': 0.08478123379540262, 'subsample': 0.675844662264745, 'colsample_bytree': 0.8920287422141442, 'gamma': 3.110593046017996}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:16,200] Trial 17 finished with value: 0.6115806371153164 and parameters: {'n_estimators': 221, 'max_depth': 10, 'learning_rate': 0.19846327374156095, 'subsample': 0.7545572175615282, 'colsample_bytree': 0.6391315139166902, 'gamma': 3.6007934675992637}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:16,435] Trial 18 finished with value: 0.613790696469786 and parameters: {'n_estimators': 133, 'max_depth': 8, 'learning_rate': 0.10673473314505406, 'subsample': 0.7782772873373861, 'colsample_bytree': 0.7149194084091065, 'gamma': 4.9877028669171155}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:16,729] Trial 19 finished with value: 0.6003924602831284 and parameters: {'n_estimators': 179, 'max_depth': 8, 'learning_rate': 0.20021988055759035, 'subsample': 0.6649724654964053, 'colsample_bytree': 0.8691071976381017, 'gamma': 2.617112781185902}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:17,053] Trial 20 finished with value: 0.6138182332876024 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.07370292540925824, 'subsample': 0.8258497085683398, 'colsample_bytree': 0.7175831103898663, 'gamma': 4.259385213450129}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:17,338] Trial 21 finished with value: 0.6139345009992909 and parameters: {'n_estimators': 226, 'max_depth': 9, 'learning_rate': 0.14665635473186345, 'subsample': 0.8297203948776009, 'colsample_bytree': 0.6496257176485347, 'gamma': 4.402657638146032}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:17,637] Trial 22 finished with value: 0.614350388201394 and parameters: {'n_estimators': 229, 'max_depth': 10, 'learning_rate': 0.14243928933732167, 'subsample': 0.748919613234605, 'colsample_bytree': 0.6335458511257921, 'gamma': 4.163700610029242}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:17,907] Trial 23 finished with value: 0.6151118005724535 and parameters: {'n_estimators': 209, 'max_depth': 9, 'learning_rate': 0.2083148948499873, 'subsample': 0.837157123883765, 'colsample_bytree': 0.6805617196691071, 'gamma': 4.621222140927572}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:18,181] Trial 24 finished with value: 0.6116817385047554 and parameters: {'n_estimators': 182, 'max_depth': 8, 'learning_rate': 0.2981634256616672, 'subsample': 0.8658676080241393, 'colsample_bytree': 0.6071190506812255, 'gamma': 3.4248428868765197}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:18,475] Trial 25 finished with value: 0.612824392919399 and parameters: {'n_estimators': 239, 'max_depth': 10, 'learning_rate': 0.13025547507849142, 'subsample': 0.771091310859972, 'colsample_bytree': 0.6558621200606968, 'gamma': 3.9212418552648765}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:18,816] Trial 26 finished with value: 0.6137099012066313 and parameters: {'n_estimators': 262, 'max_depth': 9, 'learning_rate': 0.2158116454044523, 'subsample': 0.8066239811853817, 'colsample_bytree': 0.6940444724389886, 'gamma': 4.608992502963291}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:19,073] Trial 27 finished with value: 0.6141405532218559 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.17594773770566005, 'subsample': 0.7016869364271128, 'colsample_bytree': 0.7504435205668379, 'gamma': 4.162587288446186}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:19,394] Trial 28 finished with value: 0.6123431095736448 and parameters: {'n_estimators': 276, 'max_depth': 8, 'learning_rate': 0.10571492007812763, 'subsample': 0.9105180679374288, 'colsample_bytree': 0.6351381936109626, 'gamma': 4.804507059553689}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:19,695] Trial 29 finished with value: 0.6114037354849423 and parameters: {'n_estimators': 214, 'max_depth': 10, 'learning_rate': 0.2611455312110797, 'subsample': 0.8723486397720623, 'colsample_bytree': 0.6004671212686568, 'gamma': 3.167399478246577}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:19,978] Trial 30 finished with value: 0.6141009795845368 and parameters: {'n_estimators': 208, 'max_depth': 9, 'learning_rate': 0.07573655578313232, 'subsample': 0.7412924309700301, 'colsample_bytree': 0.6615008222321257, 'gamma': 4.984460369501653}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:20,243] Trial 31 finished with value: 0.6159940371323667 and parameters: {'n_estimators': 206, 'max_depth': 9, 'learning_rate': 0.22413860205551484, 'subsample': 0.8353911042381558, 'colsample_bytree': 0.6920939182376117, 'gamma': 4.554573886489267}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:20,535] Trial 32 finished with value: 0.6125951573860772 and parameters: {'n_estimators': 239, 'max_depth': 10, 'learning_rate': 0.24127907617175492, 'subsample': 0.8172686316227229, 'colsample_bytree': 0.6305329955751321, 'gamma': 3.6091494679234986}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:20,793] Trial 33 finished with value: 0.6130886976395339 and parameters: {'n_estimators': 167, 'max_depth': 9, 'learning_rate': 0.17955749770435703, 'subsample': 0.8443143481681082, 'colsample_bytree': 0.7106454578789447, 'gamma': 4.389370088785282}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:21,089] Trial 34 finished with value: 0.6119183749295337 and parameters: {'n_estimators': 204, 'max_depth': 8, 'learning_rate': 0.13668792918589895, 'subsample': 0.9023153672543824, 'colsample_bytree': 0.7461706128701008, 'gamma': 3.926293660552602}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:21,428] Trial 35 finished with value: 0.6148041433159354 and parameters: {'n_estimators': 299, 'max_depth': 9, 'learning_rate': 0.24754366633963065, 'subsample': 0.7647027084333357, 'colsample_bytree': 0.6288662067607186, 'gamma': 4.626143418534755}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:21,731] Trial 36 finished with value: 0.6127738834877724 and parameters: {'n_estimators': 225, 'max_depth': 7, 'learning_rate': 0.12104635451747368, 'subsample': 0.8882997617246968, 'colsample_bytree': 0.7913699862964235, 'gamma': 4.111930503272376}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:21,943] Trial 37 finished with value: 0.612006826488746 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.16913139992825982, 'subsample': 0.9547382139969615, 'colsample_bytree': 0.6913830602611792, 'gamma': 3.6413587272657892}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:22,384] Trial 38 finished with value: 0.6123433984538738 and parameters: {'n_estimators': 248, 'max_depth': 6, 'learning_rate': 0.022264495870246502, 'subsample': 0.8025997554340395, 'colsample_bytree': 0.6656611323593485, 'gamma': 2.199912933211218}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:23,149] Trial 39 finished with value: 0.5703780800312303 and parameters: {'n_estimators': 157, 'max_depth': 9, 'learning_rate': 0.055729667402118994, 'subsample': 0.8587307583453594, 'colsample_bytree': 0.8369377802986351, 'gamma': 0.024069250155314137}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:23,505] Trial 40 finished with value: 0.6137157742889492 and parameters: {'n_estimators': 189, 'max_depth': 8, 'learning_rate': 0.04395998325038016, 'subsample': 0.7148318662992326, 'colsample_bytree': 0.779171754132377, 'gamma': 4.438099594732237}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:23,808] Trial 41 finished with value: 0.6150280584068984 and parameters: {'n_estimators': 205, 'max_depth': 9, 'learning_rate': 0.2269014189313792, 'subsample': 0.8417351242724015, 'colsample_bytree': 0.6914621729204495, 'gamma': 4.675205802175439}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:24,117] Trial 42 finished with value: 0.6140689351527285 and parameters: {'n_estimators': 213, 'max_depth': 9, 'learning_rate': 0.1969399121509102, 'subsample': 0.8462467249802196, 'colsample_bytree': 0.6239103746202874, 'gamma': 4.72107284859116}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:24,400] Trial 43 finished with value: 0.6148905515391352 and parameters: {'n_estimators': 233, 'max_depth': 4, 'learning_rate': 0.29206784272987013, 'subsample': 0.79666657719553, 'colsample_bytree': 0.7403931244903192, 'gamma': 4.474855663068706}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:24,680] Trial 44 finished with value: 0.6124126119213633 and parameters: {'n_estimators': 216, 'max_depth': 10, 'learning_rate': 0.21905054152467443, 'subsample': 0.8804843247529085, 'colsample_bytree': 0.6741277037414994, 'gamma': 4.0330174987109935}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:24,955] Trial 45 finished with value: 0.6121262463656408 and parameters: {'n_estimators': 193, 'max_depth': 7, 'learning_rate': 0.16644673164147597, 'subsample': 0.7794929160781284, 'colsample_bytree': 0.9534534546138737, 'gamma': 3.761949515155277}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:25,301] Trial 46 finished with value: 0.6167160888888216 and parameters: {'n_estimators': 272, 'max_depth': 3, 'learning_rate': 0.11660352533957154, 'subsample': 0.8116047115938221, 'colsample_bytree': 0.647264527832858, 'gamma': 4.803635572745662}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:25,647] Trial 47 finished with value: 0.6156979427126464 and parameters: {'n_estimators': 277, 'max_depth': 3, 'learning_rate': 0.08976893779628296, 'subsample': 0.7352310990193145, 'colsample_bytree': 0.6143372994494705, 'gamma': 4.885004854539648}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:25,991] Trial 48 finished with value: 0.6151290868267436 and parameters: {'n_estimators': 272, 'max_depth': 3, 'learning_rate': 0.08561803624200816, 'subsample': 0.7312953347692949, 'colsample_bytree': 0.6175345064060744, 'gamma': 4.84157259922036}. Best is trial 11 with value: 0.6172965072257316.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:43:26,398] Trial 49 finished with value: 0.6120156994260213 and parameters: {'n_estimators': 288, 'max_depth': 3, 'learning_rate': 0.09362432492169764, 'subsample': 0.666020463901613, 'colsample_bytree': 0.6427089327927901, 'gamma': 1.5103280771374252}. Best is trial 11 with value: 0.6172965072257316.\n",
      "[I 2024-12-19 20:43:26,400] A new study created in memory with name: no-name-e01a1fd6-9719-401d-ac27-079e524fbd3e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for xgboost: {'n_estimators': 208, 'max_depth': 10, 'learning_rate': 0.19969570808437617, 'subsample': 0.7480345228273033, 'colsample_bytree': 0.6007327056030227, 'gamma': 4.974775486769139}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 20:43:29,036] Trial 0 finished with value: 0.582290759626645 and parameters: {'n_estimators': 105, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 0.7703224730290333}. Best is trial 0 with value: 0.582290759626645.\n",
      "[I 2024-12-19 20:43:30,975] Trial 1 finished with value: 0.5867509469977469 and parameters: {'n_estimators': 82, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 0.7035596898497694}. Best is trial 1 with value: 0.5867509469977469.\n",
      "[I 2024-12-19 20:43:39,198] Trial 2 finished with value: 0.5634457775921785 and parameters: {'n_estimators': 222, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 0.9383178399292939}. Best is trial 1 with value: 0.5867509469977469.\n",
      "[I 2024-12-19 20:43:40,823] Trial 3 finished with value: 0.604271230989664 and parameters: {'n_estimators': 86, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.7884469129018556}. Best is trial 3 with value: 0.604271230989664.\n",
      "[I 2024-12-19 20:43:44,576] Trial 4 finished with value: 0.6006211106267618 and parameters: {'n_estimators': 165, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 0.9323989742288635}. Best is trial 3 with value: 0.604271230989664.\n",
      "[I 2024-12-19 20:43:49,984] Trial 5 finished with value: 0.5970118655376444 and parameters: {'n_estimators': 260, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 0.7067742863120688}. Best is trial 3 with value: 0.604271230989664.\n",
      "[I 2024-12-19 20:43:53,833] Trial 6 finished with value: 0.5693256432714451 and parameters: {'n_estimators': 135, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 0.6735569379290386}. Best is trial 3 with value: 0.604271230989664.\n",
      "[I 2024-12-19 20:43:55,162] Trial 7 finished with value: 0.6058406832802189 and parameters: {'n_estimators': 91, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 0.6402174497422949}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:43:57,452] Trial 8 finished with value: 0.6057235311373715 and parameters: {'n_estimators': 179, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 0.747344196433309}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:44:01,383] Trial 9 finished with value: 0.5782761126031142 and parameters: {'n_estimators': 123, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 0.9670050576834137}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:44:02,023] Trial 10 finished with value: 0.6042117769518344 and parameters: {'n_estimators': 62, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 0.6004454122527121}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:44:03,924] Trial 11 finished with value: 0.6044542166638446 and parameters: {'n_estimators': 192, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 0.6054488100986565}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:44:06,766] Trial 12 finished with value: 0.6056919774867064 and parameters: {'n_estimators': 171, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 0.8513554565780548}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:44:11,465] Trial 13 finished with value: 0.5862120506304027 and parameters: {'n_estimators': 219, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 0.6591083704073623}. Best is trial 7 with value: 0.6058406832802189.\n",
      "[I 2024-12-19 20:44:15,978] Trial 14 finished with value: 0.6059470125001548 and parameters: {'n_estimators': 273, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 0.8533900386276184}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:22,683] Trial 15 finished with value: 0.5920021662003188 and parameters: {'n_estimators': 274, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 0.8816461683179178}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:31,146] Trial 16 finished with value: 0.5771160527578588 and parameters: {'n_estimators': 298, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 0.8630116538771924}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:35,982] Trial 17 finished with value: 0.6010211852076478 and parameters: {'n_estimators': 240, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': 0.8141136817753951}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:40,135] Trial 18 finished with value: 0.5821312536277938 and parameters: {'n_estimators': 148, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 0.832144569668542}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:41,112] Trial 19 finished with value: 0.6044866813872862 and parameters: {'n_estimators': 52, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 0.8963853014054854}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:46,194] Trial 20 finished with value: 0.583173667231257 and parameters: {'n_estimators': 208, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 0.7384881124108029}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:48,663] Trial 21 finished with value: 0.6056682929784521 and parameters: {'n_estimators': 193, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 0.7550487129692349}. Best is trial 14 with value: 0.6059470125001548.\n",
      "[I 2024-12-19 20:44:52,580] Trial 22 finished with value: 0.6069813644074559 and parameters: {'n_estimators': 292, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 0.6492393174505139}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:44:57,000] Trial 23 finished with value: 0.6058271734228634 and parameters: {'n_estimators': 296, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 0.6396675688938283}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:01,223] Trial 24 finished with value: 0.6026487422929695 and parameters: {'n_estimators': 259, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 0.6382463951907464}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:07,179] Trial 25 finished with value: 0.5905980606175644 and parameters: {'n_estimators': 274, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 0.7042150311904747}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:11,159] Trial 26 finished with value: 0.6059668949839361 and parameters: {'n_estimators': 242, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 0.8024178771586425}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:14,024] Trial 27 finished with value: 0.6017437793420236 and parameters: {'n_estimators': 243, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 0.8008496525251796}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:19,013] Trial 28 finished with value: 0.6057443960321788 and parameters: {'n_estimators': 281, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 0.9054646268406064}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:24,468] Trial 29 finished with value: 0.5965846710686834 and parameters: {'n_estimators': 247, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 0.826406654146402}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:31,515] Trial 30 finished with value: 0.578347555302719 and parameters: {'n_estimators': 285, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 0.7739549740331064}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:35,837] Trial 31 finished with value: 0.6055259432884919 and parameters: {'n_estimators': 260, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 0.7228992035579785}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:37,336] Trial 32 finished with value: 0.6069216459705857 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 0.6733941184978802}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:38,874] Trial 33 finished with value: 0.6052808019489156 and parameters: {'n_estimators': 117, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 0.6668476224164573}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:46,397] Trial 34 finished with value: 0.564649564499627 and parameters: {'n_estimators': 226, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 0.7791587152549042}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:53,436] Trial 35 finished with value: 0.5968603989803315 and parameters: {'n_estimators': 287, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 0.9965217926403974}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:57,800] Trial 36 finished with value: 0.605906411005641 and parameters: {'n_estimators': 269, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 0.8444531068186096}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:45:59,752] Trial 37 finished with value: 0.605321154068189 and parameters: {'n_estimators': 150, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 0.6833407099199977}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:01,791] Trial 38 finished with value: 0.5995947535525482 and parameters: {'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 0.7965802856204068}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:07,830] Trial 39 finished with value: 0.5917138287570595 and parameters: {'n_estimators': 230, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': 0.9245104086744036}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:09,238] Trial 40 finished with value: 0.604110828423774 and parameters: {'n_estimators': 75, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 0.8667407158293541}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:13,529] Trial 41 finished with value: 0.606129082064232 and parameters: {'n_estimators': 266, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.8347121267005383}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:16,992] Trial 42 finished with value: 0.6054551637193609 and parameters: {'n_estimators': 253, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 0.8159287958779587}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:19,844] Trial 43 finished with value: 0.6027736786380932 and parameters: {'n_estimators': 267, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.6872829691938809}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:24,202] Trial 44 finished with value: 0.6060734042690207 and parameters: {'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.628707372000133}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:28,988] Trial 45 finished with value: 0.6030818988627438 and parameters: {'n_estimators': 299, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.6157323195186859}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:33,156] Trial 46 finished with value: 0.6059734118410468 and parameters: {'n_estimators': 286, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.6192062187655911}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:37,287] Trial 47 finished with value: 0.6059954812522151 and parameters: {'n_estimators': 285, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.6208841877955694}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:43,267] Trial 48 finished with value: 0.5846872653981124 and parameters: {'n_estimators': 283, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.6501002791607102}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:48,521] Trial 49 finished with value: 0.598456792129937 and parameters: {'n_estimators': 299, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 0.6279050020363347}. Best is trial 22 with value: 0.6069813644074559.\n",
      "[I 2024-12-19 20:46:48,525] A new study created in memory with name: no-name-52830ec6-ecb5-400e-8897-ef7f20a3b991\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random_forest: {'n_estimators': 292, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 0.6492393174505139}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 20:46:49,311] Trial 0 finished with value: 0.6200515358896064 and parameters: {'n_estimators': 230, 'max_depth': 9, 'learning_rate': 0.0212402726568262, 'subsample': 0.7259614626563833, 'colsample_bytree': 0.8758441425988741, 'gamma': 0.7407317326689533}. Best is trial 0 with value: 0.6200515358896064.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:49,734] Trial 1 finished with value: 0.6240923798408509 and parameters: {'n_estimators': 276, 'max_depth': 7, 'learning_rate': 0.06644251062462836, 'subsample': 0.8475617349895112, 'colsample_bytree': 0.8562976150738247, 'gamma': 1.0549534469284754}. Best is trial 1 with value: 0.6240923798408509.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:50,011] Trial 2 finished with value: 0.6349468233535763 and parameters: {'n_estimators': 243, 'max_depth': 9, 'learning_rate': 0.13381515897965937, 'subsample': 0.8727616834817481, 'colsample_bytree': 0.8557498766955332, 'gamma': 3.298899356027464}. Best is trial 2 with value: 0.6349468233535763.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:50,271] Trial 3 finished with value: 0.6390048304993703 and parameters: {'n_estimators': 179, 'max_depth': 9, 'learning_rate': 0.04116318115003986, 'subsample': 0.9256925902365261, 'colsample_bytree': 0.6997723045468919, 'gamma': 4.94472328644478}. Best is trial 3 with value: 0.6390048304993703.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:50,660] Trial 4 finished with value: 0.6416015715183092 and parameters: {'n_estimators': 226, 'max_depth': 4, 'learning_rate': 0.011370651277351713, 'subsample': 0.6306085133602378, 'colsample_bytree': 0.6023849099606987, 'gamma': 2.405050096020873}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:50,857] Trial 5 finished with value: 0.6398683194763198 and parameters: {'n_estimators': 104, 'max_depth': 4, 'learning_rate': 0.04568079251440286, 'subsample': 0.7280101916848545, 'colsample_bytree': 0.6479997425174644, 'gamma': 4.005197142514783}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:51,037] Trial 6 finished with value: 0.6337227450614186 and parameters: {'n_estimators': 63, 'max_depth': 4, 'learning_rate': 0.011975289390096287, 'subsample': 0.9570734884347233, 'colsample_bytree': 0.8408457419174258, 'gamma': 0.021199048807873377}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:51,326] Trial 7 finished with value: 0.6192762327560759 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.1414955845297595, 'subsample': 0.6058536585717146, 'colsample_bytree': 0.7409601612122593, 'gamma': 1.0413146795681612}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:51,588] Trial 8 finished with value: 0.6379520578346511 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.03228481588981392, 'subsample': 0.8311391875407084, 'colsample_bytree': 0.9554535022355592, 'gamma': 0.9434840955485208}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:51,905] Trial 9 finished with value: 0.6267355207627752 and parameters: {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.056958050587519446, 'subsample': 0.9637655908777434, 'colsample_bytree': 0.7625609767478605, 'gamma': 0.9116415376795012}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:52,319] Trial 10 finished with value: 0.6406941399524922 and parameters: {'n_estimators': 197, 'max_depth': 6, 'learning_rate': 0.010274074047280654, 'subsample': 0.6026427887009491, 'colsample_bytree': 0.6069045253506296, 'gamma': 2.288489177993693}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:52,760] Trial 11 finished with value: 0.6410801599597593 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.010864735452258247, 'subsample': 0.6050371459334575, 'colsample_bytree': 0.6009899147415444, 'gamma': 2.3545158049379316}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:53,229] Trial 12 finished with value: 0.6402337655716223 and parameters: {'n_estimators': 214, 'max_depth': 7, 'learning_rate': 0.01916230095298159, 'subsample': 0.6721730246403022, 'colsample_bytree': 0.6599287484887129, 'gamma': 2.352959492977959}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:53,601] Trial 13 finished with value: 0.6378228128148518 and parameters: {'n_estimators': 290, 'max_depth': 3, 'learning_rate': 0.2649533375607791, 'subsample': 0.6740860170443901, 'colsample_bytree': 0.6063405158966806, 'gamma': 3.2198623181032953}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:54,010] Trial 14 finished with value: 0.6383552497252353 and parameters: {'n_estimators': 162, 'max_depth': 6, 'learning_rate': 0.017868321922559303, 'subsample': 0.7606470056851622, 'colsample_bytree': 0.692108570859667, 'gamma': 1.8071677786489775}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:54,551] Trial 15 finished with value: 0.6394851644948473 and parameters: {'n_estimators': 256, 'max_depth': 5, 'learning_rate': 0.013576785039129001, 'subsample': 0.6703631267704163, 'colsample_bytree': 0.9770431237337491, 'gamma': 3.1357325991164666}. Best is trial 4 with value: 0.6416015715183092.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:54,924] Trial 16 finished with value: 0.6431145638875729 and parameters: {'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.028595938100383394, 'subsample': 0.6330342445175294, 'colsample_bytree': 0.6024554105649235, 'gamma': 1.7927256888523386}. Best is trial 16 with value: 0.6431145638875729.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:55,252] Trial 17 finished with value: 0.6421449652234069 and parameters: {'n_estimators': 163, 'max_depth': 3, 'learning_rate': 0.02712854421515049, 'subsample': 0.7834669659402912, 'colsample_bytree': 0.734173882505938, 'gamma': 1.6272485846788978}. Best is trial 16 with value: 0.6431145638875729.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:55,606] Trial 18 finished with value: 0.6420937563708169 and parameters: {'n_estimators': 155, 'max_depth': 3, 'learning_rate': 0.028842387257855418, 'subsample': 0.7847100565609246, 'colsample_bytree': 0.7851993407391427, 'gamma': 1.5303170456064266}. Best is trial 16 with value: 0.6431145638875729.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:55,805] Trial 19 finished with value: 0.6430936127480974 and parameters: {'n_estimators': 77, 'max_depth': 3, 'learning_rate': 0.07777968772017761, 'subsample': 0.8999698625483122, 'colsample_bytree': 0.7328582872534894, 'gamma': 1.6956145322814449}. Best is trial 16 with value: 0.6431145638875729.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:56,013] Trial 20 finished with value: 0.6286280969780146 and parameters: {'n_estimators': 54, 'max_depth': 5, 'learning_rate': 0.10463000187188294, 'subsample': 0.9163758321337597, 'colsample_bytree': 0.8145416362514903, 'gamma': 0.1640369980775347}. Best is trial 16 with value: 0.6431145638875729.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:56,236] Trial 21 finished with value: 0.6434209279610265 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.08359321907426334, 'subsample': 0.8958209140851656, 'colsample_bytree': 0.7281828709654623, 'gamma': 1.694819697487964}. Best is trial 21 with value: 0.6434209279610265.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:56,444] Trial 22 finished with value: 0.6434252460928468 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.09334189129594901, 'subsample': 0.8777736305298732, 'colsample_bytree': 0.6963401649368037, 'gamma': 1.6643477928355968}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:56,637] Trial 23 finished with value: 0.6415230061967397 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.2071681322095354, 'subsample': 0.8313170796220269, 'colsample_bytree': 0.6629854076723075, 'gamma': 2.903089722447347}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:56,866] Trial 24 finished with value: 0.640997669110665 and parameters: {'n_estimators': 108, 'max_depth': 4, 'learning_rate': 0.09254069319446258, 'subsample': 0.9843934625227653, 'colsample_bytree': 0.7046865169209894, 'gamma': 2.080826912429943}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:57,157] Trial 25 finished with value: 0.6334056204939612 and parameters: {'n_estimators': 141, 'max_depth': 8, 'learning_rate': 0.1479674086006038, 'subsample': 0.8780662201229614, 'colsample_bytree': 0.6419672887669143, 'gamma': 1.273031221832594}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:57,428] Trial 26 finished with value: 0.6388910499515111 and parameters: {'n_estimators': 93, 'max_depth': 5, 'learning_rate': 0.04151770955391877, 'subsample': 0.8617554459200992, 'colsample_bytree': 0.6836154605072783, 'gamma': 1.9539665462212392}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:57,905] Trial 27 finished with value: 0.6082991768285627 and parameters: {'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.0727600217432861, 'subsample': 0.9353808544345183, 'colsample_bytree': 0.9065083610675728, 'gamma': 0.5264473905530502}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:58,116] Trial 28 finished with value: 0.6418687070778387 and parameters: {'n_estimators': 76, 'max_depth': 3, 'learning_rate': 0.09493720541719765, 'subsample': 0.8255251793592469, 'colsample_bytree': 0.7761757804152428, 'gamma': 1.3388470077314374}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:58,449] Trial 29 finished with value: 0.6431310647566137 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.05376031454965007, 'subsample': 0.7412163793583498, 'colsample_bytree': 0.8091285181760152, 'gamma': 2.777802642801931}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:58,766] Trial 30 finished with value: 0.6409845554328312 and parameters: {'n_estimators': 179, 'max_depth': 4, 'learning_rate': 0.054480790526475864, 'subsample': 0.7178475042201317, 'colsample_bytree': 0.9152817408175036, 'gamma': 3.683984473191107}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:59,100] Trial 31 finished with value: 0.6392193796460354 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.11529123882363256, 'subsample': 0.7169222435098308, 'colsample_bytree': 0.825523650225858, 'gamma': 1.9930723806312312}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:59,463] Trial 32 finished with value: 0.6412611709702262 and parameters: {'n_estimators': 221, 'max_depth': 4, 'learning_rate': 0.05240230818365117, 'subsample': 0.7509210034587694, 'colsample_bytree': 0.7990949273369913, 'gamma': 2.704406439320525}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:46:59,920] Trial 33 finished with value: 0.6359220341183421 and parameters: {'n_estimators': 244, 'max_depth': 3, 'learning_rate': 0.06652047398638623, 'subsample': 0.8897821797998614, 'colsample_bytree': 0.7533668016553285, 'gamma': 0.5569307287543528}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:00,294] Trial 34 finished with value: 0.6415903037872511 and parameters: {'n_estimators': 177, 'max_depth': 3, 'learning_rate': 0.03414734067979545, 'subsample': 0.8080354160663775, 'colsample_bytree': 0.7243113169092488, 'gamma': 1.3588839870552945}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:00,623] Trial 35 finished with value: 0.6422701603839552 and parameters: {'n_estimators': 151, 'max_depth': 4, 'learning_rate': 0.023608899314103107, 'subsample': 0.6433920762142892, 'colsample_bytree': 0.8730164876245837, 'gamma': 2.8372380014638887}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:00,912] Trial 36 finished with value: 0.6431667845188466 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.1838070557567616, 'subsample': 0.8526800434090392, 'colsample_bytree': 0.6289178961798172, 'gamma': 3.764454556029022}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:01,187] Trial 37 finished with value: 0.6428033870560949 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.17005072133575092, 'subsample': 0.857571717734021, 'colsample_bytree': 0.6298715963476356, 'gamma': 4.553246171932022}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:01,394] Trial 38 finished with value: 0.6381612733720429 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.21922025518810553, 'subsample': 0.8965713047552822, 'colsample_bytree': 0.7127847457226699, 'gamma': 4.43071411295458}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:01,735] Trial 39 finished with value: 0.6380305253263664 and parameters: {'n_estimators': 239, 'max_depth': 5, 'learning_rate': 0.08263673977125677, 'subsample': 0.929966178672717, 'colsample_bytree': 0.6734476261098997, 'gamma': 4.917949683433533}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:01,944] Trial 40 finished with value: 0.6416379873287447 and parameters: {'n_estimators': 98, 'max_depth': 4, 'learning_rate': 0.12326876983241072, 'subsample': 0.8484847828193512, 'colsample_bytree': 0.6291518252243236, 'gamma': 3.5785207426813104}. Best is trial 22 with value: 0.6434252460928468.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:02,271] Trial 41 finished with value: 0.6434753406910473 and parameters: {'n_estimators': 209, 'max_depth': 3, 'learning_rate': 0.16329003519969132, 'subsample': 0.6975782227141417, 'colsample_bytree': 0.6326926782114536, 'gamma': 3.779263400491446}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:02,571] Trial 42 finished with value: 0.6424832060651621 and parameters: {'n_estimators': 210, 'max_depth': 4, 'learning_rate': 0.19338445785010056, 'subsample': 0.6994886610405441, 'colsample_bytree': 0.6482265429202264, 'gamma': 4.012637865906385}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:02,847] Trial 43 finished with value: 0.6411619260496894 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.2958929911989531, 'subsample': 0.7610084306125953, 'colsample_bytree': 0.6277028233829129, 'gamma': 3.8160788884195127}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:03,107] Trial 44 finished with value: 0.6423938223494492 and parameters: {'n_estimators': 169, 'max_depth': 3, 'learning_rate': 0.17012291387646564, 'subsample': 0.8086197959827939, 'colsample_bytree': 0.6808002522727894, 'gamma': 3.452223417291912}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:03,431] Trial 45 finished with value: 0.6401723472566379 and parameters: {'n_estimators': 228, 'max_depth': 5, 'learning_rate': 0.14571139037709815, 'subsample': 0.7468438677481107, 'colsample_bytree': 0.7555728535218615, 'gamma': 2.6141932423372567}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:03,780] Trial 46 finished with value: 0.6408412047500879 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.11331136025800041, 'subsample': 0.6940157768222546, 'colsample_bytree': 0.8373576659039978, 'gamma': 4.282811610541821}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:04,027] Trial 47 finished with value: 0.6358629009153925 and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.23822847267296518, 'subsample': 0.8733274301375032, 'colsample_bytree': 0.7108864421854155, 'gamma': 3.050511681584239}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:04,223] Trial 48 finished with value: 0.6390352220821934 and parameters: {'n_estimators': 64, 'max_depth': 4, 'learning_rate': 0.06249659276082738, 'subsample': 0.7894251407424926, 'colsample_bytree': 0.6662574085726913, 'gamma': 3.9848336692145785}. Best is trial 41 with value: 0.6434753406910473.\n",
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_7600\\3930955610.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2024-12-19 20:47:04,563] Trial 49 finished with value: 0.6408610526072688 and parameters: {'n_estimators': 213, 'max_depth': 3, 'learning_rate': 0.048731739968837055, 'subsample': 0.9521443848433393, 'colsample_bytree': 0.6927331399837597, 'gamma': 3.3581788945831765}. Best is trial 41 with value: 0.6434753406910473.\n",
      "[I 2024-12-19 20:47:04,564] A new study created in memory with name: no-name-473894c1-1d25-4ceb-ba77-6632bbf57f7f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for xgboost: {'n_estimators': 209, 'max_depth': 3, 'learning_rate': 0.16329003519969132, 'subsample': 0.6975782227141417, 'colsample_bytree': 0.6326926782114536, 'gamma': 3.779263400491446}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 20:47:09,030] Trial 0 finished with value: 0.6317075993926534 and parameters: {'n_estimators': 278, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.9060167842798403}. Best is trial 0 with value: 0.6317075993926534.\n",
      "[I 2024-12-19 20:47:10,993] Trial 1 finished with value: 0.5951366672837264 and parameters: {'n_estimators': 63, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 0.8063960291176899}. Best is trial 0 with value: 0.6317075993926534.\n",
      "[I 2024-12-19 20:47:17,504] Trial 2 finished with value: 0.6028790272124743 and parameters: {'n_estimators': 230, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 0.880295376453907}. Best is trial 0 with value: 0.6317075993926534.\n",
      "[I 2024-12-19 20:47:19,146] Trial 3 finished with value: 0.6009722173544033 and parameters: {'n_estimators': 60, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 0.8794890893163934}. Best is trial 0 with value: 0.6317075993926534.\n",
      "[I 2024-12-19 20:47:23,516] Trial 4 finished with value: 0.6329916671411885 and parameters: {'n_estimators': 243, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 0.9335832990187177}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:28,646] Trial 5 finished with value: 0.6296180256441732 and parameters: {'n_estimators': 230, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 0.9067082916702471}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:32,322] Trial 6 finished with value: 0.5929859664848445 and parameters: {'n_estimators': 141, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 0.7683221882021861}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:37,609] Trial 7 finished with value: 0.6302953963402013 and parameters: {'n_estimators': 263, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 0.8402736930377794}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:40,783] Trial 8 finished with value: 0.6300478217872788 and parameters: {'n_estimators': 248, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 0.9853335306393783}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:42,680] Trial 9 finished with value: 0.6120302580310338 and parameters: {'n_estimators': 92, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 0.6591882055551835}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:47,669] Trial 10 finished with value: 0.6165856390457704 and parameters: {'n_estimators': 183, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 0.9924460079372607}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:51,400] Trial 11 finished with value: 0.6297042076830784 and parameters: {'n_estimators': 296, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 0.9375093626067122}. Best is trial 4 with value: 0.6329916671411885.\n",
      "[I 2024-12-19 20:47:56,233] Trial 12 finished with value: 0.6342331333045194 and parameters: {'n_estimators': 292, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 0.7435518357312773}. Best is trial 12 with value: 0.6342331333045194.\n",
      "[I 2024-12-19 20:47:59,919] Trial 13 finished with value: 0.6315178970128356 and parameters: {'n_estimators': 205, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 0.7023816338372896}. Best is trial 12 with value: 0.6342331333045194.\n",
      "[I 2024-12-19 20:48:06,591] Trial 14 finished with value: 0.6160828112656974 and parameters: {'n_estimators': 296, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 0.7413538353485671}. Best is trial 12 with value: 0.6342331333045194.\n",
      "[I 2024-12-19 20:48:08,873] Trial 15 finished with value: 0.6343639573314216 and parameters: {'n_estimators': 155, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 0.6546614669739845}. Best is trial 15 with value: 0.6343639573314216.\n",
      "[I 2024-12-19 20:48:11,452] Trial 16 finished with value: 0.6213083390800374 and parameters: {'n_estimators': 136, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 0.6094176890496538}. Best is trial 15 with value: 0.6343639573314216.\n",
      "[I 2024-12-19 20:48:14,448] Trial 17 finished with value: 0.6108558427413983 and parameters: {'n_estimators': 144, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 0.66394076694124}. Best is trial 15 with value: 0.6343639573314216.\n",
      "[I 2024-12-19 20:48:17,128] Trial 18 finished with value: 0.6345615800339096 and parameters: {'n_estimators': 186, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.6135134033567805}. Best is trial 18 with value: 0.6345615800339096.\n",
      "[I 2024-12-19 20:48:20,262] Trial 19 finished with value: 0.6238201033604834 and parameters: {'n_estimators': 170, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 0.6008153226953779}. Best is trial 18 with value: 0.6345615800339096.\n",
      "[I 2024-12-19 20:48:22,438] Trial 20 finished with value: 0.6076748560866817 and parameters: {'n_estimators': 104, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 0.6618104493211108}. Best is trial 18 with value: 0.6345615800339096.\n",
      "[I 2024-12-19 20:48:25,777] Trial 21 finished with value: 0.6342934235765404 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.7193858431573695}. Best is trial 18 with value: 0.6345615800339096.\n",
      "[I 2024-12-19 20:48:28,357] Trial 22 finished with value: 0.6358973940265135 and parameters: {'n_estimators': 195, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.6422439970270597}. Best is trial 22 with value: 0.6358973940265135.\n",
      "[I 2024-12-19 20:48:30,529] Trial 23 finished with value: 0.6361462329055247 and parameters: {'n_estimators': 166, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 0.622058762746084}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:32,935] Trial 24 finished with value: 0.633741358564216 and parameters: {'n_estimators': 206, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 0.6284462773032429}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:36,442] Trial 25 finished with value: 0.625418179923361 and parameters: {'n_estimators': 175, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 0.6954360710606662}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:38,100] Trial 26 finished with value: 0.636053009311964 and parameters: {'n_estimators': 122, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 0.6332520324611028}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:39,450] Trial 27 finished with value: 0.6330210161583992 and parameters: {'n_estimators': 110, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.6329337770389604}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:41,162] Trial 28 finished with value: 0.6344267563181832 and parameters: {'n_estimators': 113, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 0.6880637495370577}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:42,899] Trial 29 finished with value: 0.631908346469452 and parameters: {'n_estimators': 125, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.7913093214153815}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:43,864] Trial 30 finished with value: 0.6293882141519389 and parameters: {'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 0.6373001738987311}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:46,814] Trial 31 finished with value: 0.6359580528780927 and parameters: {'n_estimators': 158, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 0.6184853122558573}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:49,786] Trial 32 finished with value: 0.6350010045707027 and parameters: {'n_estimators': 162, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 0.6860753207435435}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:52,515] Trial 33 finished with value: 0.6359782506759525 and parameters: {'n_estimators': 155, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 0.637618055226779}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:56,306] Trial 34 finished with value: 0.6245444220939763 and parameters: {'n_estimators': 153, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 0.6744714404931252}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:58,012] Trial 35 finished with value: 0.6305173244878565 and parameters: {'n_estimators': 128, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 0.6220671196890142}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:48:59,985] Trial 36 finished with value: 0.6267122314940948 and parameters: {'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.7212215569517736}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:04,580] Trial 37 finished with value: 0.6334717597127683 and parameters: {'n_estimators': 224, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 0.8400941000479062}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:06,048] Trial 38 finished with value: 0.5994484295421 and parameters: {'n_estimators': 50, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 0.6057287231025498}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:10,096] Trial 39 finished with value: 0.5947261108330691 and parameters: {'n_estimators': 123, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 0.6508805490052713}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:13,885] Trial 40 finished with value: 0.6300429774396432 and parameters: {'n_estimators': 164, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 0.7162461310983921}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:17,129] Trial 41 finished with value: 0.6359678260598798 and parameters: {'n_estimators': 191, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 0.6398036153553116}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:19,374] Trial 42 finished with value: 0.6338197034859737 and parameters: {'n_estimators': 152, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 0.6319983667481752}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:24,078] Trial 43 finished with value: 0.6342762550758354 and parameters: {'n_estimators': 214, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 0.6749482612014119}. Best is trial 23 with value: 0.6361462329055247.\n",
      "[I 2024-12-19 20:49:27,182] Trial 44 finished with value: 0.6361641591980257 and parameters: {'n_estimators': 178, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 0.6205596835720937}. Best is trial 44 with value: 0.6361641591980257.\n",
      "[I 2024-12-19 20:49:31,309] Trial 45 finished with value: 0.6320943108395484 and parameters: {'n_estimators': 186, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 0.6522246591188873}. Best is trial 44 with value: 0.6361641591980257.\n",
      "[I 2024-12-19 20:49:33,792] Trial 46 finished with value: 0.631889229096449 and parameters: {'n_estimators': 176, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 0.6769068918772346}. Best is trial 44 with value: 0.6361641591980257.\n",
      "[I 2024-12-19 20:49:36,046] Trial 47 finished with value: 0.6339652267307839 and parameters: {'n_estimators': 141, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 0.6006039810811894}. Best is trial 44 with value: 0.6361641591980257.\n",
      "[I 2024-12-19 20:49:42,767] Trial 48 finished with value: 0.6160243659956447 and parameters: {'n_estimators': 241, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 0.642125108306501}. Best is trial 44 with value: 0.6361641591980257.\n",
      "[I 2024-12-19 20:49:47,630] Trial 49 finished with value: 0.634441320864901 and parameters: {'n_estimators': 221, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 0.7661930195429305}. Best is trial 44 with value: 0.6361641591980257.\n",
      "c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:49:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random_forest: {'n_estimators': 178, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 0.6205596835720937}\n",
      "xgboost AUC: 0.6228, Log Loss: 0.4094\n",
      "random_forest AUC: 0.6198, Log Loss: 0.4099\n",
      "xgboost AUC: 0.6198, Log Loss: 0.4145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:49:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest AUC: 0.6166, Log Loss: 0.4157\n"
     ]
    }
   ],
   "source": [
    "# Execute the Two-Model Approach with Optuna usng function \"two_model_approach_with_optuna\"\n",
    "model_treatment_xgboost, model_control_randomforest, model_treatment_randomforest, model_control_xgboost = two_model_approach_with_optuna(X_train, X_test, y_train, y_test, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Two-Model Approach\n",
    "def two_model_approach(X_train, y_train, t_train, X_test):\n",
    "    model_treatment = RandomForestClassifier(random_state=42)\n",
    "    model_control = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Train separate models for treatment and control\n",
    "    model_treatment.fit(X_train[t_train == 1], y_train[t_train == 1])\n",
    "    model_control.fit(X_train[t_train == 0], y_train[t_train == 0])\n",
    "\n",
    "    # Predict probabilities\n",
    "    uplift_treatment = model_treatment.predict_proba(X_test)[:, 1]\n",
    "    uplift_control = model_control.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    uplift = uplift_treatment - uplift_control\n",
    "    return uplift\n",
    "\n",
    "uplift_two_model = two_model_approach(X_train, y_train, t_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. S-Learner\n",
    "def single_model(X_train, y_train, t_train, X_test):\n",
    "    X_train_s = X_train.copy()\n",
    "    X_train_s['treatment'] = t_train\n",
    "\n",
    "    X_test_s = X_test.copy()\n",
    "    X_test_s['treatment'] = 1  # Predict as if treated\n",
    "    X_test_c = X_test.copy()\n",
    "    X_test_c['treatment'] = 0  # Predict as if control\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train_s, y_train)\n",
    "\n",
    "    uplift_treatment = model.predict_proba(X_test_s)[:, 1]\n",
    "    uplift_control = model.predict_proba(X_test_c)[:, 1]\n",
    "\n",
    "    uplift = uplift_treatment - uplift_control\n",
    "    return uplift\n",
    "\n",
    "uplift_s_learner = single_model(X_train, y_train, t_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Enhanced Qini Evaluation\n",
    "def evaluate_qini(uplift, y_test, t_test, model_name):\n",
    "    qini = qini_auc_score(y_test, uplift, t_test)\n",
    "\n",
    "    # Use a loop to calculate uplift at different percentages\n",
    "    k_values = [i / 100 for i in range(1, 100)]  # Generate k as float values from 0.01 to 1\n",
    "    uplift_cumulative = []\n",
    "\n",
    "    for k in k_values:\n",
    "        uplift_k = uplift_at_k(y_test, uplift, t_test, strategy='overall', k=k)\n",
    "        uplift_cumulative.append(uplift_k)\n",
    "\n",
    "    print(f\"{model_name} Qini Score: {qini:.4f}\")\n",
    "\n",
    "    # Plot the Qini Curve\n",
    "    plt.plot(k_values, uplift_cumulative, label=f'{model_name} Model')\n",
    "    plt.plot([0, 1], [0, max(uplift_cumulative)], '--', label='Random')\n",
    "    plt.xlabel('Proportion of Population Targeted')\n",
    "    plt.ylabel('Cumulative Uplift')\n",
    "    plt.title(f'Qini Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Compare Two-Model and S-Learner\n",
    "print(\"### Two-Model Approach Evaluation ###\")\n",
    "evaluate_qini(uplift_two_model, y_test, t_test, \"Two-Model\")\n",
    "\n",
    "print(\"### S-Learner Evaluation ###\")\n",
    "evaluate_qini(uplift_s_learner, y_test, t_test, \"S-Learner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Tabular Comparison of Qini Scores\n",
    "qini_two_model = qini_auc_score(y_test, uplift_two_model, t_test)\n",
    "qini_s_learner = qini_auc_score(y_test, uplift_s_learner, t_test)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Two-Model', 'S-Learner'],\n",
    "    'Qini Score': [qini_two_model, qini_s_learner]\n",
    "})\n",
    "print(\"\\n### Qini Score Comparison ###\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
